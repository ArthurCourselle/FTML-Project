{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97d7a65-de3f-4791-bd96-ebdab93afdfd",
   "metadata": {},
   "source": [
    "# Classification on a given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe79eb-9c82-4026-95a9-3e5ec1b4c84a",
   "metadata": {},
   "source": [
    "We first import the necessary libraries for the exercice and load the data from the given files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bb32e6f-79c0-4d73-a9bd-ca15f0b54846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load_data():\n",
    "    path = \"data/classification/\"\n",
    "    X_train = np.load(path + \"X_train.npy\")\n",
    "    y_train = np.load(path + \"y_train.npy\")\n",
    "    X_test = np.load(path + \"X_test.npy\")\n",
    "    y_test = np.load(path + \"y_test.npy\")\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e9c86-7044-4fe9-a02e-ea8cd03ad54c",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Before trying anything on the classification. We analyse the train data, see the different classes and the repartition of the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42a50830-7324-42ae-bb4b-0a2d12043abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2000, 30)\n",
      "y_train shape: (2000,)\n",
      "Missing values in X_train: 0\n",
      "Missing values in X_test: 0\n",
      "Feature means (train): [ 0.00278456  0.0258194  -0.02816605 -0.02500212  0.00163257]\n",
      "Feature stds (train): [0.97941116 0.98730757 0.97436539 0.96622428 2.54260032]\n",
      "Class distribution: {0: 1019, 1: 981}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"Missing values in X_train:\", np.isnan(X_train).sum())\n",
    "print(\"Missing values in X_test:\", np.isnan(X_test).sum())\n",
    "\n",
    "print(\"Feature means (train):\", np.mean(X_train, axis=0)[:5])\n",
    "print(\"Feature stds (train):\", np.std(X_train, axis=0)[:5])\n",
    "\n",
    "unique_classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(unique_classes, counts)))\n",
    "\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Training Label Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e684ef-b66a-41d7-88de-1223c41795f6",
   "metadata": {},
   "source": [
    "## 📊 Dataset Analysis\n",
    "\n",
    "- The dataset contains **2000 training samples** with **30 features**.\n",
    "- The **target variable** is **binary** and **evenly balanced** between class 0 and class 1.\n",
    "- There are **no missing values** in either the training or test sets.\n",
    "- Feature values are already **approximately standardized**:\n",
    "  - Means are close to 0\n",
    "  - Most standard deviations are close to 1, with one slightly higher (~2.5)\n",
    "- Moderate dimensionality (p < n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af059f55-bb8a-478d-93de-3eb7c09fe3a2",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "We will use a scaller on a separate value to test its influence on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1398ff30-4267-4bcb-9625-ff883421263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e92119-ea5d-4dc9-b7b3-9f3e3f7cd28a",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "We will use the linear regression as a base score to compare other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd730727-4a61-45dc-bd00-19a41b8624a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test Accuracy (rounded prediction): 0.7435\n",
      "Linear Regression Test Accuracy (rounded prediction): 0.7440\n"
     ]
    }
   ],
   "source": [
    "def logistic_Regression(X_train, X_test, y_train, y_test):\n",
    "    linreg = LogisticRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_linreg = linreg.predict(X_test)\n",
    "    y_pred_class = (y_pred_linreg >= 0.5).astype(int)\n",
    "    \n",
    "    accuracy_linreg = accuracy_score(y_test, y_pred_class)\n",
    "    print(f\"Linear Regression Test Accuracy (rounded prediction): {accuracy_linreg:.4f}\")\n",
    "    return accuracy_linreg\n",
    "\n",
    "linear_acc =  logistic_Regression(X_train, X_test, y_train, y_test)\n",
    "linear_acc_scaled =  logistic_Regression(X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34382d11-61c5-4e7d-81d0-50c85ea9c8ad",
   "metadata": {},
   "source": [
    "# Support Vector Classifier (SVC)\n",
    "\n",
    "The goal of SVC is to determine a frontier between the 0 and 1 classes.  \n",
    "In this algorithm, we have to be careful, as Maximum Margin Classifiers are very sensitive to outliers.  \n",
    "We therefore need a threshold (`C` parameter) that allows misclassifications when necessary to improve generalization.\n",
    "\n",
    "We will try three different approaches to draw that decision boundary:\n",
    "\n",
    "- **Linear kernel**: builds a straight line as the frontier between classes.\n",
    "- **RBF kernel**: draws a Gaussian-shaped curve to separate the data.\n",
    "- **Polynomial kernel**: builds a polynomial curve to adapt to more complex patterns.\n",
    "\n",
    "\n",
    "To maximize the model’s accuracy, we will tune important **hyperparameters** (`C`, `degree`, `gamma`, `coef0`) for each kernel.  \n",
    "Here, `degree` controls the complexity of the polynomial kernel, `gamma` defines how far the influence of a single training example reaches (used in RBF and poly), and `coef0` is a constant term that affects how flexible the polynomial decision boundary is.\n",
    "\n",
    "Hopefully, we will be able to draw conclusions about the data from the different results and see which model fits the task best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "afb1f721-9076-42d5-b288-2949e24c7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVC with kernel linear (unscaled): 0.7510\n",
      "Parameters (unscaled): {'C': 0.01}\n",
      "\n",
      "Accuracy SVC with kernel linear (scaled): 0.7490\n",
      "Parameters (scaled): {'C': 1}\n",
      "\n",
      "Accuracy SVC with kernel rbf (unscaled): 0.7945\n",
      "Parameters (unscaled): {'C': 10, 'gamma': 0.1}\n",
      "\n",
      "Accuracy SVC with kernel rbf (scaled): 0.8000\n",
      "Parameters (scaled): {'C': 10, 'gamma': 0.1}\n",
      "\n",
      "Accuracy SVC with kernel poly (unscaled): 0.8995\n",
      "Parameters (unscaled): {'C': 0.03, 'coef0': 0, 'degree': 3, 'gamma': 0.1}\n",
      "\n",
      "Accuracy SVC with kernel poly (scaled): 0.8080\n",
      "Parameters (scaled): {'C': 0.03, 'coef0': 1, 'degree': 3, 'gamma': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_param(kernel, param):\n",
    "\n",
    "    # sans scaler\n",
    "    grid = GridSearchCV(SVC(kernel=kernel), param, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    y_pred =  best_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy SVC with kernel {kernel} (unscaled): {test_acc:.4f}\")\n",
    "    print(f\"Parameters (unscaled): {best_params}\\n\")\n",
    "    \n",
    "    # avec scaler\n",
    "    grid = GridSearchCV(SVC(kernel=kernel), param, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    y_pred =  best_model.predict(X_test_scaled)\n",
    "    test_acc_scalled = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy SVC with kernel {kernel} (scaled): {test_acc_scalled:.4f}\")\n",
    "    print(f\"Parameters (scaled): {best_params}\\n\")\n",
    "    \n",
    "    return (test_acc, test_acc_scalled)\n",
    "\n",
    "param_grid_linear = {'C': [0.01, 0.1, 1, 10]}\n",
    "(linear_test_acc, linear_test_acc_scalled) = get_param('linear', param_grid_linear)\n",
    "\n",
    "param_grid_rbf = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "(rbf_test_acc, rbf_test_acc_scalled) = get_param('rbf', param_grid_rbf)\n",
    "\n",
    "param_grid_poly = {\n",
    "    'C': [0.03, 0.05, 0.1, 1],\n",
    "    'coef0': [0, 1],\n",
    "    'gamma': [0.01, 0.1],\n",
    "    'degree': [1, 2, 3]\n",
    "}\n",
    "\n",
    "(poly_test_acc, poly_test_acc_scalled) = get_param('poly', param_grid_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b331607-09c9-4eb2-87b4-230617b810f9",
   "metadata": {},
   "source": [
    "### Results SVC\n",
    "\n",
    "The polynomial kernel gives the best results, which suggests that the decision boundaries between classes are neither linear nor easily captured by a Gaussian curve (RBF kernel). Instead, the separation is more complex and better modeled by a polynomial of degree 3.\n",
    "\n",
    "Interestingly, the unscaled data performs better, which may indicate that the feature magnitudes themselves carry meaningful information. Scaling might be distorting this natural structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c45bf2-ba9d-4f87-bbab-ad501992479b",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN is a learning algorithm that makes predictions by looking at the **K closest samples** in the training set and assigning the most frequent class among them.\n",
    "\n",
    "To optimize performance, we tune several parameters:\n",
    "\n",
    "- **`n_neighbors`**:  Number of neighbors to consider (K). A low value can be sensitive to noise, while a high value may underfit.\n",
    "- **`weights`**:  \n",
    "  - `'uniform'`: all neighbors contribute equally.  \n",
    "  - `'distance'`: closer neighbors contribute more.\n",
    "- **`p`** : \n",
    "  - `p = 1`: Manhattan distance.  \n",
    "  - `p = 2`: Euclidean distance (default).\n",
    "\n",
    "- **`leaf_size`**:  Changes the speed and memory of the algorithm.\n",
    "\n",
    "We compare results with and without scaling to evaluate how much it impacts KNN’s performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b4b72d7d-e37f-476b-a5bf-d15ba318dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN (unscaled): 0.7925\n",
      "Parameters (unscaled): {'leaf_size': 5, 'n_neighbors': 14, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Accuracy KNN (scaled): 0.7780\n",
      "Parameters (scaled): {'leaf_size': 5, 'n_neighbors': 18, 'p': 1, 'weights': 'distance'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_knn_param(param):\n",
    "    # sans scaler\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_param = grid.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy KNN (unscaled): {test_acc:.4f}\")\n",
    "    print(f\"Parameters (unscaled): {best_param}\\n\")\n",
    "\n",
    "    # avec scaler\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_param = grid.best_params_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    test_acc_scaled = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy KNN (scaled): {test_acc_scaled:.4f}\")\n",
    "    print(f\"Parameters (scaled): {best_param}\\n\")\n",
    "\n",
    "    return test_acc, test_acc_scaled\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': list(range(1, 21)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],  # distance : 1=Manathan 2=Euclidienne\n",
    "    'leaf_size': [5, 10, 20, 30, 50] \n",
    "}\n",
    "\n",
    "(knn_acc, knn_acc_scaled) = get_knn_param(param_grid_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54663749-f561-46fb-b328-2485d87f9b59",
   "metadata": {},
   "source": [
    "### Results KNN\n",
    "\n",
    "In this case again, the unscaled data gives better performance. This confirms that the original feature scales might contain useful information, here on a distance-based model like KNN. The best results were obtained using the Euclidean distance (`p=2`) and `distance` based weighting, which gives closer neighbors more influence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd4fdb-cf7a-4dcc-8e13-815540b840c8",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "Ensembling combines multiple different models to make a final prediction, with the goal of improving overall performance.  \n",
    "Since we’ve already trained several strong classifiers individually, we’ll now test whether combining them can boost accuracy on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5deb654c-63ca-4310-b167-3d5358a1d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc individual accuracy: 0.8995\n",
      "knn individual accuracy: 0.7925\n",
      "Ensemble Accuracy (VotingClassifier soft): 0.8715\n",
      "Ensemble Accuracy (VotingClassifier hard): 0.8995\n"
     ]
    }
   ],
   "source": [
    "clf2 = SVC(C=0.03, kernel='poly', coef0=0, gamma=0.1, probability=True)\n",
    "clf3 = KNeighborsClassifier(leaf_size=5, n_neighbors=14, weights='distance', p=2)\n",
    "\n",
    "models = [('svc', clf2), ('knn', clf3)]\n",
    "for name, clf in models:\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(f\"{name} individual accuracy: {acc:.4f}\")\n",
    "\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', clf2),\n",
    "        ('knn', clf3)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[3, 2]  # SVC = better accu = bigger weight\n",
    ")\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', clf2),\n",
    "        ('knn', clf3)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    weights=[3, 2] # SVC = better accu = bigger weight\n",
    ")\n",
    "\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "y_pred = voting_clf_soft.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Ensemble Accuracy (VotingClassifier soft): {acc:.4f}\")\n",
    "\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "y_pred = voting_clf_hard.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Ensemble Accuracy (VotingClassifier hard): {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a80b6-2639-4109-8de4-2612d2c781b0",
   "metadata": {},
   "source": [
    "###  Analysis: Why Ensembling Didn't Improve Accuracy\n",
    "\n",
    "Despite testing both **soft** and **hard** voting strategies (with and without weighting), the ensemble model does **not outperform** the individual SVC classifier.\n",
    "\n",
    "- **Soft Voting** combines class probabilities. Even when giving higher weight to the SVC, the ensemble **lower than the SVC alone (0.8995)**.\n",
    "- **Hard Voting** relies on majority class predictions. When we weight SVC more heavily, the ensemble behaves similarly to the SVC itself—matching but not exceeding its performance.\n",
    "\n",
    "The models in the ensemble tend to make **similar predictions** or when they differ, the weaker models (e.g., KNN or AdaBoost) often introduce noise rather than useful diversity. As a result, the ensemble's vote is pulled slightly away from the strongest model (SVC), reducing overall accuracy. In this case, the ensemble doesn’t help because SVC already performs significantly better, and combining it with less accurate models degrades the final result.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
